# 🎙️Speech Emotion Recognition (SER) Project

## 🎯Project Description

The Speech Emotion Recognition (SER) project aims to develop a system that detects emotions from speech signals in real-time using machine learning models. It involves data collection, preprocessing, feature extraction, model training, evaluation, and deployment for real-time applications.

### Features
1. 🔊Mel Frequency Cepstral Coefficients (MFCCs): Captures spectral characteristics of the audio signal.
2. 🎼Formant Frequencies: Represents resonance frequencies that correlate with vocal tract shape and emotional states.
3. 🎚️Pitch and Pitch Contour: Analyzes variations in the fundamental frequency of the speech signal.
4. ⏱️Speech Rate: Measures the rate of speech to detect emotional arousal.
5. 🔋Energy: Reflects the intensity or loudness of the speech signal.
6. ⚡Zero Crossing Rate: Captures the temporal dynamics of the speech signal.

### Project Workflow
- 📂Data Collection: Gather labeled speech samples for training.
- 🧹Preprocessing: Standardize and clean the audio data for consistency.
- Feature Extraction: Extract key features like MFCCs, pitch, formant frequencies, etc.
- 🧠Model Training: Train machine learning models such as SVM, CNN, or RNN.
- Model Evaluation: Assess performance using accuracy and F1-score.

### Dependencies
- Python 3.x
- Libraries: numpy, scikit-learn, librosa, tensorflow or pytorch, google.colab

### 📂 Project Demo Link:
- Youtube: https://www.youtube.com/watch?v=y2ouYjRfGxM

### Social Links
- LinkedIn: https://www.linkedin.com/in/supriyanagpal
- Medium: https://medium.com/@thesupriyanagpal
- Twitter: https://x.com/imsupriyanagpal
- Youtube: https://www.youtube.com/@supriyanagpal
